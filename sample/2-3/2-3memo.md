# word2vec

## one-hot 表現

- ベクトルの要素の中で 1 つだけが 1 で残りがすべて 0 であるようなベクトル → これを入力層とする
  - これに重みを掛けることは重みの行ベクトル(=分散表現)を「抜き出す」ことに相当する

## CBOW(continuous bag-of-words)

- コンテキストを入力し，ターゲットを推測することを目的とした NN
  - 入力層: コンテキスト(one-hot 表現)を単語数だけ入力層として別々に用意する
  - 中間層: それらに共通の重みで全結合層に入力し平均を取る
  - 出力層: 中間層とは別の重みで全結合層に入力し出力をスコアとする(Softmax 関数を適用することで確率とできる)
  - 入力層 → 中間層の全結合層の重み(の各行)が(各)単語の分散表現となる → 意味がエンコードされる
    - 中間層 → 出力層の全結合層の重み(の各列)にも(各)単語の分散表現が格納されるが，こちらはあまりに使われない
    - 全結合層は MatMul レイヤ (バイアスがないため)
  - 学習: Softmax とクロスエントロピー誤差を用いるだけ

## 学習データ
- コーパスからコンテキストとターゲットを作成する
